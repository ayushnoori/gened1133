{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Analysis of Uncle Tom's Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Set font as Arial\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads the text from a file and returns it as a string.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "text = load_text(\"data/uncle_toms_cabin.txt\")\n",
    "\n",
    "# Truncate at 1000000 characters\n",
    "text_truncated = text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def get_doc(text: str):\n",
    "    \"\"\"\n",
    "    Process text with SpaCy for further analysis.\n",
    "    \"\"\"\n",
    "    return nlp(text)\n",
    "\n",
    "# Example usage:\n",
    "doc = get_doc(text_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print document statistics\n",
    "print(f\"Document statistics:\")\n",
    "print(f\"  - Number of sentences: {len(list(doc.sents))}\")\n",
    "print(f\"  - Number of tokens: {len(doc)}\")\n",
    "print(f\"  - Number of unique tokens: {len(set(doc))}\")\n",
    "print(f\"  - Number of named entities: {len([ent for ent in doc.ents if ent.label_ == 'PERSON'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_aliases = {\n",
    "    # 1. Uncle Tom\n",
    "    \"Uncle Tom\": [\n",
    "        \"Uncle Tom\",\n",
    "        \"Tom\",\n",
    "        \"UNCLE TOM\",    # All-caps variant\n",
    "        \"Uncle Tom’s\"   # Possessive form\n",
    "    ],\n",
    "\n",
    "    # 2. Aunt Chloe\n",
    "    \"Aunt Chloe\": [\n",
    "        \"Aunt Chloe\",\n",
    "        \"Chloe\",\n",
    "        # Variants that appear with punctuation/line breaks:\n",
    "        \"Aunt\\nChloe\", \n",
    "        \"Aunt Chloe,—“I\"\n",
    "    ],\n",
    "\n",
    "    # 3. Eliza Harris\n",
    "    \"Eliza Harris\": [\n",
    "        \"Eliza Harris\",\n",
    "        \"Eliza\",\n",
    "        \"Mrs. Harris\",\n",
    "        # Common dialect/spelling variants:\n",
    "        \"Liza\",\n",
    "        \"Lizzy\",\n",
    "        \"Lizy\",\n",
    "        # The text sometimes shows her name with punctuation/line breaks:\n",
    "        \"Eliza\\n\",             \n",
    "        \"Eliza trembled\",      \n",
    "        \"Eliza glided\\nforward\",\n",
    "        \"Eliza tremulously\",  \n",
    "        # You may want to strip punctuation/line breaks depending on your approach\n",
    "    ],\n",
    "\n",
    "    # 4. George Harris\n",
    "    \"George Harris\": [\n",
    "        \"George Harris\",\n",
    "        \"George\",\n",
    "        \"Mr. Harris\",\n",
    "        # Occasionally split across lines in the text:\n",
    "        \"George\\nHarris\"\n",
    "    ],\n",
    "\n",
    "    # 5. Evangeline \"Eva\" St. Clare\n",
    "    \"Evangeline \\\"Eva\\\" St. Clare\": [\n",
    "        \"Eva\",\n",
    "        \"Little Eva\",\n",
    "        \"Miss Eva\",\n",
    "        \"Evangeline St. Clare\",\n",
    "        \"Evangeline \\\"Eva\\\" St. Clare\",\n",
    "        \"Eva.\"  # sometimes appears with punctuation\n",
    "    ],\n",
    "\n",
    "    # 6. Augustine St. Clare\n",
    "    \"Augustine St. Clare\": [\n",
    "        \"Augustine\",\n",
    "        \"Mr. St. Clare\",\n",
    "        \"Master St. Clare\",\n",
    "        \"Augustine St. Clare\",\n",
    "        # Variants/punctuation from text:\n",
    "        \"St. Clare\",\n",
    "        \"Augustine St.\\nClare\",\n",
    "        \"Augustine St.\"\n",
    "    ],\n",
    "\n",
    "    # 7. Marie St. Clare\n",
    "    \"Marie St. Clare\": [\n",
    "        \"Marie\",\n",
    "        \"Mrs. St. Clare\",\n",
    "        \"Marie St. Clare\",\n",
    "        \"Miss\\nMarie\",       # appears with a line break\n",
    "        \"Marie St. Clare’s\"  # possessive form\n",
    "    ],\n",
    "\n",
    "    # 8. Miss Ophelia (Ophelia St. Clare)\n",
    "    \"Miss Ophelia\": [\n",
    "        \"Miss Ophelia\",\n",
    "        \"Ophelia\",\n",
    "        \"Cousin Ophelia\",\n",
    "        # Sometimes referred to with last name or line breaks:\n",
    "        \"Ophelia St. Clare\",\n",
    "        \"Miss\\nOphelia\",\n",
    "        # Topsy’s nickname for her:\n",
    "        \"Feely\",\n",
    "        \"Feeley\",\n",
    "        \"Phelia\"\n",
    "    ],\n",
    "\n",
    "    # 9. Topsy\n",
    "    \"Topsy\": [\n",
    "        \"Topsy\"\n",
    "        # No major variants found for Topsy in the extracted text\n",
    "    ],\n",
    "\n",
    "    # 10. Simon Legree\n",
    "    \"Simon Legree\": [\n",
    "        \"Simon Legree\",\n",
    "        \"Legree\",\n",
    "        \"Master Legree\",\n",
    "        \"Simon\"\n",
    "    ],\n",
    "\n",
    "    # 11. Cassy\n",
    "    \"Cassy\": [\n",
    "        \"Cassy\",\n",
    "        \"Cass\"\n",
    "    ],\n",
    "\n",
    "    # 12. Emmeline\n",
    "    \"Emmeline\": [\n",
    "        \"Emmeline\"\n",
    "        # Sometimes with punctuation: \"Emmeline.\"\n",
    "    ],\n",
    "\n",
    "    # 13. George Shelby\n",
    "    \"George Shelby\": [\n",
    "        \"George Shelby\",\n",
    "        \"Mas’r George\",\n",
    "        \"Master George\",\n",
    "        \"Georgey\"  # Dialect form in text\n",
    "    ],\n",
    "\n",
    "    # 14. Mr. Shelby (Arthur Shelby)\n",
    "    \"Mr. Shelby\": [\n",
    "        \"Mr. Shelby\",\n",
    "        \"Arthur Shelby\",\n",
    "        \"Arthur\",\n",
    "        \"Shelby\"  # sometimes just last name in the text\n",
    "    ],\n",
    "\n",
    "    # 15. Mrs. Shelby (Emily Shelby)\n",
    "    \"Mrs. Shelby\": [\n",
    "        \"Mrs. Shelby\",\n",
    "        \"Emily Shelby\",\n",
    "        \"Emily\"\n",
    "    ],\n",
    "\n",
    "    # 16. Sam\n",
    "    \"Sam\": [\n",
    "        \"Sam\",\n",
    "        \"Black Sam\"  # frequently called “Black Sam” in dialect passages\n",
    "    ],\n",
    "\n",
    "    # 17. Quimbo\n",
    "    \"Quimbo\": [\n",
    "        \"Quimbo\"\n",
    "        # no additional variants found in extracted list\n",
    "    ],\n",
    "\n",
    "    # 18. Phineas Fletcher\n",
    "    \"Phineas Fletcher\": [\n",
    "        \"Phineas Fletcher\",\n",
    "        \"Phineas\"\n",
    "    ],\n",
    "\n",
    "    # 19. Tom Loker\n",
    "    \"Tom Loker\": [\n",
    "        \"Tom Loker\",\n",
    "        \"Loker\"\n",
    "    ],\n",
    "\n",
    "    # 20. Mr. Haley\n",
    "    \"Mr. Haley\": [\n",
    "        \"Mr. Haley\",\n",
    "        \"Haley\",\n",
    "        \"Dan Haley\"  # occasionally appears as “Dan Haley” in some editions/contexts\n",
    "    ]\n",
    "}\n",
    "\n",
    "minor_character_aliases = {\n",
    "    # Eliza’s young son:\n",
    "    \"Harry Harris\": [\n",
    "        \"Harry\",\n",
    "        \"Little Harry\",\n",
    "        \"Harry Harris\"\n",
    "    ],\n",
    "\n",
    "    # Frequently just “Andy” in the Shelby household:\n",
    "    \"Andy\": [\n",
    "        \"Andy\"\n",
    "    ],\n",
    "\n",
    "    # Other slaves or servants on the Shelby plantation:\n",
    "    \"Black Jake\": [\n",
    "        \"Jake\",\n",
    "        \"Black Jake\"\n",
    "    ],\n",
    "    \"Mose\": [\n",
    "        \"Mose\"\n",
    "    ],\n",
    "    \"Pete\": [\n",
    "        \"Pete\"\n",
    "    ],\n",
    "    \"Polly\": [\n",
    "        \"Polly\"\n",
    "    ],\n",
    "    \"Jinny\": [\n",
    "        \"Jinny\"\n",
    "    ],\n",
    "    \"Aunt Sally\": [\n",
    "        \"Sally\",\n",
    "        \"Aunt Sally\"\n",
    "    ],\n",
    "    \n",
    "    # Occasional references:\n",
    "    \"Tom Lincon\": [\n",
    "        \"Tom Lincon\"\n",
    "    ],\n",
    "\n",
    "    # Another servant name that pops up occasionally:\n",
    "    \"Mandy\": [\n",
    "        \"Mandy\"\n",
    "    ],\n",
    "\n",
    "    # The Birds (Senator Bird & Mrs. Bird), who help Eliza:\n",
    "    \"Senator Bird\": [\n",
    "        \"Mr. Bird\",\n",
    "        \"Senator Bird\",\n",
    "        \"John Bird\",\n",
    "        \"Bird\"\n",
    "    ],\n",
    "    \"Mrs. Bird\": [\n",
    "        \"Mrs. Bird\",\n",
    "        \"Mary Bird\",\n",
    "        \"Mary\"\n",
    "    ],\n",
    "    \n",
    "    # House servants at the Bird home:\n",
    "    \"Cudjoe\": [\n",
    "        \"Cudjoe\",\n",
    "        \"Uncle Cudjoe\"\n",
    "    ],\n",
    "    \"Aunt Dinah\": [\n",
    "        \"Aunt Dinah\",\n",
    "        \"Dinah\"\n",
    "    ],\n",
    "\n",
    "    # Minor characters associated with Quaker settlement:\n",
    "    \"Rachel Halliday\": [\n",
    "        \"Rachel Halliday\",\n",
    "        \"Rachel\"\n",
    "    ],\n",
    "    \"Simeon Halliday\": [\n",
    "        \"Simeon Halliday\",\n",
    "        \"Simeon\"\n",
    "    ],\n",
    "    \"Ruth Stedman\": [\n",
    "        \"Ruth Stedman\",\n",
    "        \"Ruth\"\n",
    "    ],\n",
    "\n",
    "    # Another Quaker or friend in the novel:\n",
    "    \"John Van Trompe\": [\n",
    "        \"John Van Trompe\"\n",
    "        # occasionally just \"John,\" but there are MANY “John” references, so be cautious\n",
    "    ],\n",
    "\n",
    "    # Another escaping slave or contact:\n",
    "    \"Lucy\": [\n",
    "        \"Lucy\"\n",
    "    ],\n",
    "\n",
    "    # On Legree’s plantation:\n",
    "    \"Sambo\": [\n",
    "        \"Sambo\"\n",
    "    ],\n",
    "    # We already had Quimbo in top 20.\n",
    "\n",
    "    # Servants in St. Clare’s household:\n",
    "    \"Adolph\": [\n",
    "        \"Adolph\",\n",
    "        \"Dolph\"\n",
    "    ],\n",
    "    \"Mammy\": [\n",
    "        \"Mammy\"\n",
    "    ],\n",
    "    # Some editions also mention \"Mammy\" by an actual name, but in text she’s usually just “Mammy.”\n",
    "\n",
    "    # Alfred St. Clare (Augustine’s brother):\n",
    "    \"Alfred St. Clare\": [\n",
    "        \"Alfred St. Clare\",\n",
    "        \"Alfred\",\n",
    "        \"Uncle Alfred\"\n",
    "    ],\n",
    "    # His son, cousin to Eva:\n",
    "    \"Henrique St. Clare\": [\n",
    "        \"Henrique\",\n",
    "        \"Cousin Henrique\"\n",
    "    ],\n",
    "\n",
    "    # Prue, the enslaved woman in New Orleans (meets tragic end):\n",
    "    \"Prue\": [\n",
    "        \"Prue\"\n",
    "    ],\n",
    "\n",
    "    # Another enslaved woman purchased by Legree alongside Emmeline:\n",
    "    \"Susan\": [\n",
    "        \"Susan\",\n",
    "        \"Susan.\"\n",
    "    ],\n",
    "\n",
    "    # Madame de Thoux (George Harris’s sister in some later chapters):\n",
    "    \"Madame de Thoux\": [\n",
    "        \"Madame de Thoux\",\n",
    "        \"De Thoux\"\n",
    "    ],\n",
    "\n",
    "    # Old Bruno is the Shelby family’s dog, occasionally mentioned by name:\n",
    "    \"Bruno\": [\n",
    "        \"Bruno\",\n",
    "        \"Old Bruno\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Add minor characters to character aliases\n",
    "character_aliases.update(minor_character_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize names\n",
    "def harmonize_name(entity_text, verbose=True):\n",
    "    for canonical, aliases in character_aliases.items():\n",
    "        if entity_text in aliases:\n",
    "            return canonical\n",
    "    if verbose:\n",
    "        print(f\"{entity_text}\", end=', ')\n",
    "    return \"Other\"\n",
    "\n",
    "# Extract sentences for characters\n",
    "def extract_sentences_for_characters(doc):\n",
    "    \"\"\"\n",
    "    For each person entity, accumulate the sentences in which they appear.\n",
    "    Returns a dictionary mapping {character_name: [sentences]}.\n",
    "    \"\"\"\n",
    "\n",
    "    char_sentences = defaultdict(list)\n",
    "    num_sents = len(list(doc.sents))\n",
    "    for sent in tqdm(doc.sents, total=num_sents, desc=\"Extracting sentences for characters\"):\n",
    "        person_entities = [ent.text for ent in sent.ents if ent.label_ == \"PERSON\"]\n",
    "        for person in person_entities:\n",
    "            canonical_name = harmonize_name(person, verbose=False)\n",
    "            char_sentences[canonical_name].append(sent.text)\n",
    "    return char_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_per_character = extract_sentences_for_characters(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_character_sentiments(sentences_per_character):\n",
    "    character_sentiments = {}\n",
    "    \n",
    "    for character, sentences in tqdm(sentences_per_character.items(), total=len(sentences_per_character), desc=\"Analyzing character sentiments\"):\n",
    "        if not sentences:\n",
    "            continue\n",
    "        \n",
    "        polarities = []\n",
    "        for s in sentences:\n",
    "            blob = TextBlob(s)\n",
    "            polarities.append(blob.sentiment.polarity)\n",
    "        \n",
    "        avg_polarity = sum(polarities)/len(polarities) if polarities else 0\n",
    "        \n",
    "        # Store distribution\n",
    "        distribution = {\n",
    "            'negative': sum(p < -0.1 for p in polarities),\n",
    "            'neutral': sum(-0.1 <= p <= 0.1 for p in polarities),\n",
    "            'positive': sum(p > 0.1 for p in polarities)\n",
    "        }\n",
    "        \n",
    "        character_sentiments[character] = {\n",
    "            'num_references': len(sentences),\n",
    "            'avg_polarity': avg_polarity,\n",
    "            'distribution': distribution,\n",
    "            'all_polarities': polarities,\n",
    "        }\n",
    "    \n",
    "    return character_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_sentiments = analyze_character_sentiments(sentences_per_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_character_word_freqs(sentences_per_character):\n",
    "    char_word_freqs = {}\n",
    "    adj_word_freqs = {}\n",
    "    for character, sentences in tqdm(sentences_per_character.items(), total=len(sentences_per_character), desc=\"Analyzing character word frequencies\"):\n",
    "        tokens = []\n",
    "        adj_tokens = []\n",
    "        for text in sentences:\n",
    "            # Process with spaCy\n",
    "            doc_ = nlp(text)\n",
    "            for token in doc_:\n",
    "                # Filter out stop words, punctuation, etc.\n",
    "                if token.is_stop or token.is_punct or token.is_space:\n",
    "                    continue\n",
    "                tokens.append(token.lemma_.lower())\n",
    "                if token.pos_ == \"ADJ\":\n",
    "                    adj_tokens.append(token.lemma_.lower())\n",
    "        freqs = Counter(tokens)\n",
    "        adj_freqs = Counter(adj_tokens)\n",
    "        char_word_freqs[character] = freqs.most_common(40)\n",
    "        adj_word_freqs[character] = adj_freqs.most_common(40)\n",
    "    return char_word_freqs, adj_word_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_word_freqs, adj_word_freqs = analyze_character_word_freqs(sentences_per_character)\n",
    "\n",
    "# Characters to include\n",
    "characters_to_include = [\n",
    "    \"Uncle Tom\",\n",
    "    \"Aunt Chloe\",\n",
    "    \"Eliza Harris\",\n",
    "    \"George Harris\",\n",
    "    \"Evangeline \\\"Eva\\\" St. Clare\",\n",
    "    \"Augustine St. Clare\",\n",
    "    \"Marie St. Clare\",\n",
    "    \"Sam\", \"Andy\", \"Topsy\",\n",
    "    \"Simon Legree\",\n",
    "    \"Quimbo\", \"Sambo\"\n",
    "]\n",
    "\n",
    "for character in characters_to_include:\n",
    "    print(character, \":\", adj_word_freqs[character])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_chars = sorted(\n",
    "    character_sentiments.items(),\n",
    "    key=lambda x: x[1]['num_references'],\n",
    "    # key=lambda x: abs(x[1]['avg_polarity']),\n",
    "    reverse=True\n",
    ")\n",
    "# top_n = 30\n",
    "# sorted_chars = sorted_chars[:top_n]\n",
    "\n",
    "# Drop Other\n",
    "sorted_chars = [x for x in sorted_chars if x[0] != \"Other\"]\n",
    "# sorted_chars = [x for x in sorted_chars if x[0] in characters_to_include]\n",
    "\n",
    "# Sort by avg polarity\n",
    "sorted_chars = sorted(sorted_chars, key=lambda x: x[1]['avg_polarity'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the keys and values for plotting\n",
    "characters = [x[0] for x in sorted_chars]\n",
    "avg_polarities = [x[1]['avg_polarity'] for x in sorted_chars]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(characters, avg_polarities, color='skyblue', edgecolor='black', linewidth=1, zorder=10)\n",
    "\n",
    "# Optionally, color negative vs positive differently:\n",
    "for bar, val in zip(bars, avg_polarities):\n",
    "    if val < 0:\n",
    "        bar.set_color('#F7A2A1')\n",
    "        bar.set_edgecolor('black')\n",
    "    else:\n",
    "        bar.set_color('#BACBA9')\n",
    "        bar.set_edgecolor('black')\n",
    "\n",
    "# Draw line at 0\n",
    "plt.axhline(y=0, color='black', linewidth=1, linestyle='-', zorder=0)\n",
    "\n",
    "# Rotate x-axis labels if there are many characters\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.xlabel(\"Character\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Average Polarity\", fontsize=14, fontweight='bold')\n",
    "plt.grid(True, linestyle='--', alpha=0.7, zorder=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to file\n",
    "plt.savefig('results/sentiment_plot.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by num_references descending\n",
    "sorted_chars = sorted(character_sentiments.items(), \n",
    "                        key=lambda x: x[1]['num_references'], \n",
    "                        reverse=True)\n",
    "\n",
    "top_n = 30\n",
    "top_chars = sorted_chars[:top_n]\n",
    "top_chars = [x for x in top_chars if x[0] != \"Other\"]\n",
    "names = [x[0] for x in top_chars]\n",
    "counts = [x[1]['num_references'] for x in top_chars]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(names, counts, color='skyblue', edgecolor='black', linewidth=1, zorder=10)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "# plt.title(f\"Top {top_n} Characters by Number of References\")\n",
    "plt.xlabel(\"Character\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Sentence Count\", fontsize=14, fontweight='bold')\n",
    "plt.grid(True, linestyle='--', alpha=0.7, zorder=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('results/character_sentence_count.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_distribution(character_sentiments, character_name):\n",
    "    \"\"\"\n",
    "    Plot a bar chart for negative/neutral/positive distribution of a given character.\n",
    "    \"\"\"\n",
    "    if character_name not in character_sentiments:\n",
    "        print(f\"Character '{character_name}' not found in sentiments data.\")\n",
    "        return\n",
    "    \n",
    "    dist = character_sentiments[character_name]['distribution']\n",
    "    labels = list(dist.keys())   # ['negative', 'neutral', 'positive']\n",
    "    values = [dist[k] for k in labels]\n",
    "    labels = [label.capitalize() for label in labels]\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.bar(labels, values, color=['#F7A2A1', 'gray', '#BACBA9'], edgecolor='black', linewidth=1, zorder=10)\n",
    "    plt.title(f\"{character_name}\", fontsize = 14)\n",
    "    plt.xlabel(\"Sentiment\", fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Count of Sentences\", fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, zorder=0)\n",
    "\n",
    "    plt.savefig(f'results/sentiment_distribution/{character_name}.png', dpi=600, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character_name in characters_to_include:\n",
    "    plot_sentiment_distribution(character_sentiments, character_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_character_cooccurrence_network(doc):\n",
    "    \"\"\"\n",
    "    Build a co-occurrence network of characters.\n",
    "    For each sentence, if multiple characters appear, increment an edge weight between them.\n",
    "    Returns a dict of edge counts: { (charA, charB): count, ... }.\n",
    "    \"\"\"\n",
    "    cooccurrence_counts = Counter()\n",
    "    num_sents = len(list(doc.sents))\n",
    "    \n",
    "    for sent in tqdm(doc.sents, total=num_sents, desc=\"Building character co-occurrence network\"):\n",
    "        # Find person entities in the sentence\n",
    "        person_entities = [harmonize_name(ent.text, verbose=False) \n",
    "                           for ent in sent.ents \n",
    "                           if ent.label_ == \"PERSON\"]\n",
    "        \n",
    "        # Get unique characters in this sentence (avoid double-counting if name repeated)\n",
    "        unique_chars = set(person_entities)\n",
    "        unique_chars.discard(\"Other\")\n",
    "        \n",
    "        # If 2 or more chars in sentence, update pairwise co-occurrence\n",
    "        if len(unique_chars) > 1:\n",
    "            unique_chars_list = sorted(list(unique_chars))\n",
    "            for i in range(len(unique_chars_list)):\n",
    "                for j in range(i+1, len(unique_chars_list)):\n",
    "                    charA = unique_chars_list[i]\n",
    "                    charB = unique_chars_list[j]\n",
    "                    pair = tuple(sorted([charA, charB]))\n",
    "                    cooccurrence_counts[pair] += 1\n",
    "    \n",
    "    return cooccurrence_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_counts = build_character_cooccurrence_network(doc)\n",
    "min_edge_weight = 2\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Get unique characters from cooccurrence_counts\n",
    "unique_characters = list(set([char for pair in cooccurrence_counts.keys() for char in pair]))\n",
    "unique_characters.sort()\n",
    "\n",
    "# Empty interaction matrix d\n",
    "int_matrix = np.zeros((len(unique_characters), len(unique_characters)))\n",
    "\n",
    "# Add edges\n",
    "for (charA, charB), count in tqdm(cooccurrence_counts.items(), total=len(cooccurrence_counts), desc=\"Building network\"):\n",
    "    if count >= min_edge_weight:\n",
    "        G.add_edge(charA, charB, weight=count)\n",
    "\n",
    "    # Add to interaction matrix\n",
    "    int_matrix[unique_characters.index(charA), unique_characters.index(charB)] = count\n",
    "    int_matrix[unique_characters.index(charB), unique_characters.index(charA)] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the interaction matrix is symmetric\n",
    "if not np.allclose(int_matrix, int_matrix.T):\n",
    "    print(\"Warning: Interaction matrix is not symmetric.\")\n",
    "\n",
    "# Compute row sums\n",
    "row_sums = np.sum(int_matrix, axis=1)\n",
    "\n",
    "# Remove rows and columns with sum < threshold\n",
    "threshold = 10\n",
    "int_matrix_sparse = int_matrix[row_sums > threshold, :]\n",
    "int_matrix_sparse = int_matrix_sparse[:, row_sums > threshold]\n",
    "\n",
    "# Remove characters with sum < threshold\n",
    "unique_characters_sparse = np.array(unique_characters)[row_sums > threshold]\n",
    "\n",
    "# Get colormap\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"#355070\", \"#6d597a\", \"#b56576\", \"#e56b6f\", \"#eaac8b\"], N=256)\n",
    "\n",
    "# Create a clustermap\n",
    "g = sns.clustermap(\n",
    "    int_matrix_sparse,\n",
    "    method='average',        # linkage method for clustering\n",
    "    metric='euclidean',      # distance metric\n",
    "    cmap=custom_cmap,        # custom colormap\n",
    "    annot=True,              # annotate cells with the numeric values\n",
    "    xticklabels=unique_characters_sparse,\n",
    "    yticklabels=unique_characters_sparse,\n",
    "    figsize=(8, 8),         # figure size\n",
    "    linewidths=0.5,          # black border width\n",
    "    linecolor='black'        # black border color\n",
    ")\n",
    "\n",
    "plt.savefig('results/character_cooccurrence_network.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "\n",
    "# # Draw nodes\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=2000, node_color='skyblue')\n",
    "# # Draw edges\n",
    "# edge_weights = [G[u][v]['weight'] for u,v in G.edges()]\n",
    "# nx.draw_networkx_edges(G, pos, width=[w * 0.1 for w in edge_weights], edge_color='gray')\n",
    "# # Draw labels\n",
    "# nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "# plt.title(\"Character Co-occurrence Network\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
